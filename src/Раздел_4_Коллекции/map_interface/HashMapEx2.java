package Раздел_4_Коллекции.map_interface;

import java.util.HashMap;
import java.util.Map;

public class HashMapEx2 {

    public static void main(String[] args) {
        Map<Integer, String> map = new HashMap<>(16, 0.75f);
        map.put(444,"Это круто!");
        System.out.println("map = " + map);
    }

}
/*
Hashmap работает по принципам хеширование.
Хеширование - это преобразование с помощью метода hashcode любого объекта в число int;
Все объекты в Java наследуют стандартную реализацию hashcode функции, которая описывается в классе Object,
эта функция возвращает hashcode, полученный путём конвертации внутреннего адреса объекта в число, что ведёт к
созданию уникального кода для каждого отдельного объекта.
В классе Hashmap есть внутренний класс Node(узел), который часто называют Entry, так как он реализует этот интерфейс
Map.Entry<K, V> Node это именно то, что представляет для нас пару ключ-значение
Он содержит такие поля
final int hash;
final K key;
V value;
Node<K, V> next;
Если меня спросят, объясни в двух словах, что из себя представляет Hashmap. Я отвечу:
В основе Hashmap лежит массив. Элементами данного массива являются структуры LinkedList.
Данные структуры LinkedList и заполняются элементами, которые мы добавляем в Hashmap.
После создания Hashmap, создаётся массив с размером 16. Этот массив называется Table.
Каждый элемент данного массива может содержать несколько наших пар ключ-значение, которое мы будем добавлять в наш Hashmap.
Поэтому, чтобы один элемент массива мог содержать несколько пар, эти пары ключ-значение объединяются в LinkedList.
Каждый элемент массива будет содержать LinkedList. Часто элементы данного массива называется bucket(корзины), а уже в
корзинах содержится элементы Hashmap(пары ключ-значение). Когда мы добавляем элемент в Hashmap, то сначала идёт проверка
ключа на null, если равен null, то этот элемент сразу помещается на нулевой индекс. Если не null, то находится
hashcode для ключа, после чего несложным алгоритмом в Hashmap находится назначение какого индекса будет помещён данный
элемент. Если hashcode совпадают, то и индексы совпадают!
Первый вариант добавления
356
st1
7.5
null

N = 16
index считается вот так
index = hash & (n-1)
Получаем остаток от деления, и этот остаток от деления будет обозначать номер корзины.

Индекс получился 3, в него добавим объект Node.
Первое поле Node - это hashcode
Второе поле Node - это key
Третье поле Node - это value
Четвёртое поле Node - это next

Когда мы добавляем в корзину элемент, и если там уже есть элемент(-ы), то идёт проверка на hashcode этих элементов,
если нет совпадений, то элемент будет добавлен в конец.
Когда hashcode 185, то есть совпали hashcode, будет идти проверка для всех элементов LinkedList в корзине.
Если hashcode одинаковые, то идёт проверка на equals, проверяются ключи st4 и st2 равны с помощью equals, не равны.
Переходим к проверке следующему элементу и так далее.
Если 2 объекты при сравнении на equals возвращает true, и hashcode одинаковые то, новый объект будет перезаписан на
место старого, get() быстрый у Hashmap.
Находится hashcode для ключа st6 например 562, находится индекс например 7, и здесь идёт проверка, сначала по hashcode,
когда будет одинаковый hashcode, то будет сравнение через equals.

При создании HashMap мы можем задать 2 параметра, которые очень сильно влияют на производительность.
Initial capacity - начальный размер массива, который называется table.  (16 дефолтное значение)
Load factor - коэффициент того, насколько массив должен быть заполнен, после чего его массив будет увеличен вдвое.
(0.75f дефолтное значение)
16 * 0.75 = 12
После того, как в наш HashMap будет добавлено 12 элементов, размер нашего массива будет увеличен вдвое, то есть уже
будет массив из 32 элементов и все элементы HashMap будут rehashing, Rehashing произойдёт, то есть заново благодаря
hashcode, который содержит Node,
будет определяться на какой индекс нового массива будет определён тот или иной элемент, и уже возможно вот такого
LinkedList у нас не получится. Чем больше мы указываем capacity начальный,
тем больше памяти будет занимать наш массив, но тем меньше LinkedList будут образовываться внутри конкретной позиции
массива и поиск будет происходить быстрее.
Мы можем пожертвовать памятью, но выиграть во времени доступа к элементу.
Чем больше Load factor, тем больше мы будем экономить памяти, но поиск элементов будет занимать больше времени.
0.75 золотая середина между экономией памяти и экономией времени, в большинстве случаев это не меняют,
hashcode ключа может быть большим для создания массива с таким же размером, как и само значение ключа.
Если такой массив мы создадим, то получим OutOfMemoryError, будет занимать кучу памяти даже когда наш HashMap
содержит 2-3 элемента.
Чем лучше реализован hashcode, тем лучше будут использоваться ваши bucket-ы.
Для того чтобы вставить элемент и получить его на это требуется константное время - O(1)
Поиск hashcode и вычисление index очень быстрое
O(1) в лучшем случае, O(n) в худшем случае
Если hashcode возвращает всегда 3, то когда отметку достигнет 64 (определённого порога), скорость операций сильно падает,
он перестаёт это хранить в LinkedList, то вместо связных списков используются сбалансированные деревья, начиная с Java 8,
скорость операций сильно падает.
В сбалансированном дереве справа всегда находиться больший элемент, слева меньший элемент, это правило применяется везде,
то есть, если нам надо найти 16, мы проверяем 16 больше 10 да, идём вправо, 16 больше 12, идём вправо, и дальше 16 = 16

                   ----10----
                  /          \
                 7           12
              /     \      /    \
             3______ 9____11_____16

Это помогает достичь, если в LinkedList была скорость O(n), то в дереве идёт бинарный поиск O(log(n))
Очень важно использовать в качестве ключа immutable объекты.
Для нашего класса мы можем поставить final, для его полей тоже final.
Когда мы изменяем поле, и это поле участвует в hashcode, то после того, как мы захотим проверить на то,
что есть данный ключ, будет false!
Так как hashcode вычисляет, используя это поле.
HashMap not synchronized - её не надо использовать в multithreading, для этого есть ConcurrentHashMap
*/